(window.webpackJsonp=window.webpackJsonp||[]).push([[51],{470:function(t,n,e){"use strict";e.r(n);var a=e(56),r=Object(a.a)({},(function(){var t=this.$createElement,n=this._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":this.$parent.slotKey}},[n("h2",{attrs:{id:"h264转码"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#h264转码"}},[this._v("#")]),this._v(" h264转码")]),this._v(" "),n("div",{staticClass:"language-c++ extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[this._v('void H264Transcoding::h264ToMp4(const char *infile, const char *outfile){\n    // 视频流所在的输入视频的AVStream数组索引\n    int videoIdx = -1;\n    // 封装格式上下文，保存视频文件封装格式相关信息\n    AVFormatContext* pInputAVFormateContext = nullptr;\n    // 输出封装格式\n    AVOutputFormat* pAVOutputFormate = nullptr;\n    // 打开视频文件，pInputAVFormateContext是一个AVFormatContext指针(调用avformat_alloc_context分配)，如果是空指针，则在avformat_open_input中被分配\n    int ret = avformat_open_input(&pInputAVFormateContext, infile, nullptr, nullptr);\n    if(ret < 0) return;\n    qDebug() << "视频时长:" << pInputAVFormateContext->duration/1000000.0 << "s";\n    qDebug() << "视频平均混合码率:" << pInputAVFormateContext->bit_rate/1000 << "Kbps";\n\n    ret = avformat_find_stream_info(pInputAVFormateContext,nullptr);\n    if(ret != 0){\n        return;\n    }\n//    av_dump_format(pInputAVFormateContext,0,infile,0);\n\n    // 输出封装格式上下文\n    AVFormatContext* pOutputFormatContext = nullptr;\n    ret = avformat_alloc_output_context2(&pOutputFormatContext,nullptr,"mp4",outfile);\n    if(ret < 0){\n        return;\n    }\n\n    /* 通过判断outfile的格式，转化成不同格式的数据\n    pAVOutputFormate = av_guess_format(nullptr, outfile, nullptr);\n    pOutputFormatContext->oformat = pAVOutputFormate;\n    */\n\n    // 输出封装格式文件的格式设置\n    pAVOutputFormate = pOutputFormatContext->oformat;\n    // nb_sreams: 输入视频的AVStream个数\n    for(uint i = 0; i < pInputAVFormateContext->nb_streams; i++){\n        AVStream* pInputAVStream = pInputAVFormateContext->streams[i];\n        // 新建视频流\n        AVStream* pOutputAVStream = avformat_new_stream(pOutputFormatContext,nullptr);\n        // 编码器参数的设置\n        ret = avcodec_parameters_copy(pOutputAVStream->codecpar,pInputAVStream->codecpar);\n        if(ret < 0) return;\n        pOutputAVStream->codecpar->codec_tag = 0;\n    }\n\n    for(uint i = 0; i < pInputAVFormateContext->nb_streams; i++){\n        if(pInputAVFormateContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO){\n            // 找到视频流的索引\n            videoIdx = i;\n            break;\n        }\n    }\n\n//    av_dump_format(pOutputFormatContext,0,outfile,1);\n    // 打开视频流\n    ret = avio_open(&pOutputFormatContext->pb,outfile,AVIO_FLAG_WRITE);\n    if(ret < 0) return;\n    // 写入头部信息\n    ret = avformat_write_header(pOutputFormatContext, nullptr);\n    if(ret < 0) return;\n\n    AVPacket pkt;\n//    std::int64_t iistartTime = av_gettime();\n    std::int64_t iiframeIndex = 0;\n\n    while(true){\n        AVStream* pInputStream = nullptr;\n        AVStream* pOutputStream = nullptr;\n        ret = av_read_frame(pInputAVFormateContext, &pkt);\n        if(ret < 0) break;\n        emit oneFrame(pkt.size);\n        // 查看是否有做时间基的设置\n        if(pkt.pts == AV_NOPTS_VALUE){ // 没有设置时间基\n            // 时间基转换\n            AVRational time_base1 = pInputAVFormateContext->streams[videoIdx]->time_base;\n            std::int64_t iicalcDuration = (double)AV_TIME_BASE / av_q2d(pInputAVFormateContext->streams[videoIdx]->r_frame_rate);\n            pkt.pts = (double)(iiframeIndex * iicalcDuration) / (double(av_q2d(time_base1) * AV_TIME_BASE));\n            // 解码时间基(dts)\n            pkt.dts = pkt.pts;  // 没有B帧\n            // 目标两帧之间的长度\n            pkt.duration = (double)iicalcDuration / (double)(av_q2d(time_base1) * AV_TIME_BASE);\n        }\n//        if(pkt.stream_index == videoIdx){\n//            AVRational time_base = pInputAVFormateContext->streams[videoIdx]->time_base;\n//            AVRational time_base_q = {1, AV_TIME_BASE};\n//            std::int64_t pts_time = av_rescale_q(pkt.dts, time_base, time_base_q);\n//            std::int64_t now_time = av_gettime() - iistartTime;\n//        }\n\n        pInputStream = pInputAVFormateContext->streams[pkt.stream_index];\n        pOutputStream = pOutputFormatContext->streams[pkt.stream_index];\n        // 显示时间基的转换\n        pkt.pts = av_rescale_q_rnd(pkt.pts, pInputStream->time_base, pOutputStream->time_base,(AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));\n        // 解码时间基的转换\n        pkt.dts = av_rescale_q_rnd(pkt.dts, pInputStream->time_base, pOutputStream->time_base,(AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));\n        // 数据时长的设置\n        pkt.duration = (int)av_rescale_q(pkt.duration, pInputStream->time_base, pOutputStream->time_base);\n        pkt.pos = -1;\n\n        if(pkt.stream_index == videoIdx){ iiframeIndex++; }\n        // 转码后的数据包，写入目标视频信息结构体中\n        ret = av_interleaved_write_frame(pOutputFormatContext, &pkt);\n        if(ret < 0) break;\n\n        av_packet_unref(&pkt);\n    }\n    // 写入尾巴帧\n    av_write_trailer(pOutputFormatContext);\n    if(!(pOutputFormatContext->oformat->flags & AVFMT_NOFILE)){\n        // 关闭各种流\n        avio_close(pOutputFormatContext->pb);\n    }\n    avformat_free_context(pOutputFormatContext);\n\n//    avio_close(pInputAVFormateContext->pb);\n    avformat_close_input(&pInputAVFormateContext);\n\n\n}\n')])])])])}),[],!1,null,null,null);n.default=r.exports}}]);